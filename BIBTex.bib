@article{Negahdaripour:90,
author = {Shahriar Negahdaripour},
journal = {J. Opt. Soc. Am. A},
keywords = {Algorithms; Brightness; Optical flow; Photogrammetry; Surfaces; Vision},
number = {2},
pages = {279--285},
publisher = {Optica Publishing Group},
title = {Closed-form relationship between the two interpretations of a moving plane},
volume = {7},
month = {Feb},
year = {1990},
url = {https://opg.optica.org/josaa/abstract.cfm?URI=josaa-7-2-279},
doi = {10.1364/JOSAA.7.000279},
abstract = {It is well known that a pair of images of a textured planar surface captured from two different viewpoints can give rise to two interpretations for the orientation of the plane and the relative position and orientation of the camera at the two viewpoints. The relationship between these two solutions has been derived for the case in which the separation of the two viewpoints is small (one viewpoint position and orientation can be brought into coincidence with the other through an infinitesimal rotation and translation). I derive the relationship between the two interpretations for the case in which the baseline between the two camera positions can be arbitrarily large, and I show how one solution can be derived in terms of the other.},
}

@InProceedings{10.1007/3-540-47967-8_56,
author="Pollefeys, Marc
and Verbiest, Frank
and Van Gool, Luc",
editor="Heyden, Anders
and Sparr, Gunnar
and Nielsen, Mads
and Johansen, Peter",
title="Surviving Dominant Planes in Uncalibrated Structure and Motion Recovery",
booktitle="Computer Vision --- ECCV 2002",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="837--851",
abstract="In this paper we address the problem of uncalibrated structure and motion recovery from image sequences that contain dominant planes in some of the views. Traditional approaches fail when the features common to three consecutive views are all located on a plane. This happens because in the uncalibrated case there is a fundamental ambiguity in relating the structure before and after the plane. This is, however, a situation that is often hard to avoid in man-made environments. We propose a complete approach that detects the problem and defers the computation of parameters that are ambiguous in projective space (i.e. the registration between partial reconstructions only sharing a common plane and poses of cameras only seeing planar features) till after self-calibration. Also a new linear self-calibration algorithm is proposed that couples the intrinsics between multiple subsequences. The final result is a complete metric 3D reconstruction of both structure and motion for the whole sequence. Experimental results on real image sequences show that the approach yields very good results.",
isbn="978-3-540-47967-3"
}
@article{article,
author = {Fraser, Clive},
year = {2012},
month = {09},
pages = {},
title = {Evolution of network orientation procedures},
volume = {36},
journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences}
}
